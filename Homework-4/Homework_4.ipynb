{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKcu5pJ0cwHg"
      },
      "source": [
        "# Homework 4: CIFAR-10\n",
        "Applied Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gple3Yuxem1H"
      },
      "source": [
        "## Create a CNN to classify CIFAR-10\n",
        "Use the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset.\n",
        "\n",
        "You can utilize `keras.datasets.cifar10.load_data()` to import the dataset as `numpy ndarrays` or `tfds.load('cifar10')` to import the dataset as `tf.data.Dataset`.\n",
        "\n",
        "**You must utilize transfer learning and data augmentation.** Your grade will depend on the quality of your best model. Discuss the different models you tried. *Include all model parameters, accuracy, a confusion matrix, and sample misclassified images.*\n",
        "\n",
        "I suggest using data pipelines to avoid a RAM resource exhaustion error. They can be implemented fairly easily in one of two ways: \n",
        "  1. Utilize a data_augmentation function and Dataset.map(data_augmentation) to augment your training tf.data.Dataset (will require `tf.data.Dataset`s), or\n",
        "  2. Utilize Keras ImageDataGenerator, using the ImageDataGenerator to also do all preprocessing necessary and batch images (will require `np ndarray`s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRnkLqYRInRf"
      },
      "source": [
        "# using keras.datasets.cifar10.load_data() and Keras ImageDataGenerator\n",
        "\n",
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import Sequential\n",
        "# Models imported for transfer learing\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# some of the import functions only work by putting tensorflow in them. Not sure why\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkkpN3lK2VSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d67a5b-a051-4854-8846-ede3c3bc4012"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P1u_di4MUYd"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mDhlB_9pGvN",
        "outputId": "8027c594-fddb-4b74-c191-88fa0f87a4a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 32, 32, 3), (35000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXAYMmazpNHk",
        "outputId": "1efe18fd-606a-4ae8-bbff-c62fb5f807cc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15000, 32, 32, 3), (15000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYPjXVIYpRpU",
        "outputId": "0485eb2b-f07c-43bf-c0e2-5cca7edaeff5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 labels so the y shape will go from 1 to 10\n",
        "# https://www.geeksforgeeks.org/python-keras-keras-utils-to_categorical/\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "Oh2ukzMnpvKF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape, y_val.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfMdRYEpp7oM",
        "outputId": "c3b06639-8977-49e4-f84f-47e7129f5d8f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 10), (15000, 10), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation using the ImageDataGenerator\n",
        "train_generator = ImageDataGenerator(rotation_range=2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     zoom_range=0.1)\n",
        "val_generator = ImageDataGenerator(rotation_range=2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   zoom_range=0.1)\n",
        "test_generator = ImageDataGenerator(rotation_range=2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    zoom_range=0.1)\n",
        "\n",
        "# fit the generators\n",
        "train_generator.fit(X_train)\n",
        "val_generator.fit(X_val)\n",
        "test_generator.fit(X_test)"
      ],
      "metadata": {
        "id": "YoUrT6FGq7ml"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjustable learning rate using keras callbacks\n",
        "# error: monitor needed to be changed from val_accuracy to accuracy?\n",
        "learning_rate_reduce = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                         factor=0.01,\n",
        "                                         patience=3,\n",
        "                                         min_lr=1e-5)"
      ],
      "metadata": {
        "id": "QcRzIoFLsN9E"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first model uses the VGG19 model specifically designed for image recognition\n",
        "model_1 = VGG19(include_top=False,\n",
        "                weights='imagenet',\n",
        "                input_shape=(32,32,3),\n",
        "                classes=y_train.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysSLFLzRsm_8",
        "outputId": "68dd637f-38e0-42ab-b589-78b89892af72"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add finishing layers to model 1\n",
        "model = Sequential()\n",
        "model.add(model_1)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation=('relu'), input_dim=512))\n",
        "model.add(Dense(512, activation=('relu')))\n",
        "model.add(Dense(256, activation=('relu')))\n",
        "model.add(Dense(128, activation=('relu')))\n",
        "model.add(Dense(10, activation=('softmax')))\n",
        "\n",
        "model.compile(optimizer=SGD(lr=.001,\n",
        "                            momentum=.9,\n",
        "                            nesterov=False),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[tensorflow.keras.metrics.Accuracy(name=\"accuracy\", dtype=None)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VQb2Y-LuaNM",
        "outputId": "1f3f2340-344b-44a4-80d0-ffd1b83702d6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XBTLfImvBCs",
        "outputId": "9a87f2c2-6ab6-4d4d-c64e-4e22ead3ec99"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,240,010\n",
            "Trainable params: 21,240,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch_size= 100\n",
        "epochs=50\n",
        "\n",
        "learn_rate=.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "metadata": {
        "id": "zoN3KH6wwX3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data generator can be removed from the validation set in order to see\n",
        "# different results.\n",
        "# steps per epoch error fix\n",
        "# https://stackoverflow.com/questions/59864408/tensorflowyour-input-ran-out-of-data\n",
        "history = model.fit_generator(train_generator.flow(X_train, y_train, batch_size=128),\n",
        "                    epochs=50,\n",
        "                    steps_per_epoch=len(X_train)//128,\n",
        "                    validation_data=val_generator.flow(X_val, y_val, batch_size=128),\n",
        "                    #validation_data=(X_val, y_val),\n",
        "                    validation_steps=250,\n",
        "                    callbacks=[learning_rate_reduce],\n",
        "                    #callbacks=[keras.callbacks.EarlyStopping(patience=5)],\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "GkLbOAtEvBgL",
        "outputId": "15121933-b161-43c2-9c9e-b5dd6edbf839"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "273/273 [==============================] - 53s 188ms/step - loss: 0.3970 - accuracy: 2.8103e-04 - val_loss: 0.4948 - val_accuracy: 5.4000e-04 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 4.2154e-04"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-0373d6e4102f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlearning_rate_reduce\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0;31m#callbacks=[keras.callbacks.EarlyStopping(patience=5)],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CHevGC1FvPQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mD35YVHQvBU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Second model uses ResNet50, which is a deeper and more compelx model than the previous VGG19\n",
        "model_2 = ResNet50(include_top=False,\n",
        "                   weights='imagenet',\n",
        "                   input_shape=(32,32,3),\n",
        "                   classes=y_train.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogN6GaP8t29U",
        "outputId": "d924a37b-3f39-4117-beb0-a1691d732c60"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    }
  ]
}